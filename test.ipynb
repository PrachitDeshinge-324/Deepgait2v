{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cedcd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: array([[[-0.00977022, -0.00902494,  0.0239883 , ...,  0.0046846 ,\n",
      "          0.01627403,  0.00732368],\n",
      "        [ 0.0078876 ,  0.00619673, -0.01143681, ...,  0.04477644,\n",
      "         -0.01358613,  0.00123141],\n",
      "        [ 0.00944004, -0.01486732,  0.01425996, ...,  0.01205933,\n",
      "         -0.00769172,  0.00687816],\n",
      "        ...,\n",
      "        [-0.0095961 ,  0.01826757, -0.01005876, ...,  0.00894808,\n",
      "         -0.02322198,  0.00998654],\n",
      "        [ 0.01338981,  0.0174102 ,  0.01237892, ..., -0.00814528,\n",
      "          0.01694491,  0.00188178],\n",
      "        [-0.00318462, -0.00183634, -0.00169526, ..., -0.00535763,\n",
      "         -0.05251109, -0.00156175]]], dtype=float32), 3: array([[[-0.02400575, -0.00776361,  0.04141662, ...,  0.00205892,\n",
      "          0.00897689,  0.00291347],\n",
      "        [ 0.02489338,  0.01410513, -0.02063243, ...,  0.03961884,\n",
      "         -0.00390327,  0.00247639],\n",
      "        [ 0.02717591, -0.03578995,  0.02965746, ...,  0.0122497 ,\n",
      "         -0.00657685, -0.00083991],\n",
      "        ...,\n",
      "        [-0.02008373,  0.04173977, -0.02562924, ...,  0.00636481,\n",
      "         -0.01758786,  0.01225035],\n",
      "        [ 0.0333548 ,  0.02448664,  0.0296841 , ..., -0.00620857,\n",
      "          0.01223945, -0.00244321],\n",
      "        [-0.00744583,  0.00367253, -0.00842155, ..., -0.00630011,\n",
      "         -0.03618588, -0.00716534]]], dtype=float32), 4: array([[[-0.00563923, -0.01072142,  0.02268943, ...,  0.00329292,\n",
      "          0.02025777,  0.00604399],\n",
      "        [ 0.00366099,  0.00466887, -0.01082217, ...,  0.04904542,\n",
      "         -0.01746883,  0.00294931],\n",
      "        [ 0.00658237, -0.01413091,  0.01441084, ...,  0.01479969,\n",
      "         -0.00810151,  0.0092679 ],\n",
      "        ...,\n",
      "        [-0.01058773,  0.01883812, -0.01094165, ...,  0.01266035,\n",
      "         -0.02920265,  0.00899662],\n",
      "        [ 0.01094404,  0.01702625,  0.01095246, ..., -0.00670911,\n",
      "          0.01667566,  0.00054358],\n",
      "        [-0.00257261, -0.00124003, -0.00142418, ..., -0.00741994,\n",
      "         -0.06062361, -0.00285497]]], dtype=float32), 5: array([[[-0.00614791, -0.01195272,  0.02448858, ...,  0.00441572,\n",
      "          0.02291726,  0.00730616],\n",
      "        [ 0.00435147,  0.0048897 , -0.01132999, ...,  0.05655786,\n",
      "         -0.02035206,  0.00314696],\n",
      "        [ 0.00730291, -0.01529186,  0.01571047, ...,  0.01657909,\n",
      "         -0.00969304,  0.00987009],\n",
      "        ...,\n",
      "        [-0.01176283,  0.0199792 , -0.01317283, ...,  0.01207842,\n",
      "         -0.03151177,  0.01268346],\n",
      "        [ 0.0119994 ,  0.01817545,  0.01575102, ..., -0.00414676,\n",
      "          0.01703001,  0.00023315],\n",
      "        [-0.00288639,  0.00039702, -0.00305258, ..., -0.00980545,\n",
      "         -0.06726908, -0.00676234]]], dtype=float32)}\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# load the pickled data\n",
    "with open('./saved_embeddings.pkl', 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "# print the loaded data\n",
    "print(data)\n",
    "print(len(data))  # print the length of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a9ce43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1, 256, 16)\n",
      "<class 'numpy.ndarray'>\n",
      "Length : 1\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load('output/embeddings/track_3_embedding.npy', allow_pickle=True)\n",
    "# print the shape of the numpy array\n",
    "print(f'Shape: {data.shape}')  # print the shape of the numpy array\n",
    "# print the type of the numpy array\n",
    "print(type(data))  # print the type of the numpy array\n",
    "# print the length of the numpy array\n",
    "print(f'Length : {len(data)}')  # print the length of the numpy array\n",
    "# print the data type of the numpy array\n",
    "print(data.dtype)  # print the data type of the numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7364769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FAISS Index Information ---\n",
      "<faiss.swigfaiss.IndexFlatIP; proxy of <Swig Object of type 'faiss::IndexFlatIP *' at 0x111459e10> >\n",
      "Number of vectors in the index: 5\n",
      "Dimension of the vectors in the index: 4096\n",
      "Type of the index: <class 'faiss.swigfaiss.IndexFlatIP'>\n",
      "\n",
      "--- Performing a sample search ---\n",
      "Query vector shape: (1, 4096)\n",
      "Found 5 nearest neighbors:\n",
      "Distances (L2/Euclidean if IndexFlatL2): [[-0.9278428 -0.9736645 -0.995217  -1.0257723 -1.0408934]]\n",
      "FAISS Internal IDs (these are indices within the FAISS structure): [[4 3 2 0 1]]\n",
      "\n",
      "--- Retrieved Associated Data for Nearest Neighbors ---\n",
      "Rank 1: FAISS ID: 4, Name: 'Person_0004', File Path: '/data/DeepGaitV2/person_image_0004.jpg', Distance: -0.9278\n",
      "Rank 2: FAISS ID: 3, Name: 'Person_0003', File Path: '/data/DeepGaitV2/person_image_0003.jpg', Distance: -0.9737\n",
      "Rank 3: FAISS ID: 2, Name: 'Person_0002', File Path: '/data/DeepGaitV2/person_image_0002.jpg', Distance: -0.9952\n",
      "Rank 4: FAISS ID: 0, Name: 'Person_0000', File Path: '/data/DeepGaitV2/person_image_0000.jpg', Distance: -1.0258\n",
      "Rank 5: FAISS ID: 1, Name: 'Person_0001', File Path: '/data/DeepGaitV2/person_image_0001.jpg', Distance: -1.0409\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- 1. Load the FAISS index ---\n",
    "index_file_path = 'data_DeepGaitV2/person_database.index'\n",
    "\n",
    "if not os.path.exists(index_file_path):\n",
    "    print(f\"Error: FAISS index file not found at '{index_file_path}'\")\n",
    "    print(\"Please ensure the path is correct and the file exists.\")\n",
    "    # For demonstration, let's create a dummy index if it doesn't exist\n",
    "    print(\"Creating a dummy index for demonstration purposes...\")\n",
    "    dummy_dimension = 128\n",
    "    dummy_num_vectors = 1000\n",
    "    dummy_vectors = np.random.rand(dummy_num_vectors, dummy_dimension).astype('float32')\n",
    "    dummy_index = faiss.IndexFlatL2(dummy_dimension)\n",
    "    dummy_index.add(dummy_vectors)\n",
    "    faiss.write_index(dummy_index, index_file_path)\n",
    "    print(f\"Dummy index created: {index_file_path}\")\n",
    "    print(\"WARNING: This dummy index does not contain your original data.\")\n",
    "\n",
    "index = faiss.read_index(index_file_path)\n",
    "\n",
    "# --- 2. Print basic index information ---\n",
    "print(\"\\n--- FAISS Index Information ---\")\n",
    "print(index)  # Provides a summary of the index type and parameters\n",
    "print(f'Number of vectors in the index: {index.ntotal}')\n",
    "print(f'Dimension of the vectors in the index: {index.d}')\n",
    "print(f'Type of the index: {type(index)}')\n",
    "\n",
    "# --- 3. IMPORTANT: Load or Recreate your External Metadata Mapping ---\n",
    "# This is the part that connects FAISS IDs to your real-world data.\n",
    "# You MUST have created and saved this mapping when you built the index.\n",
    "# If you don't have this, you cannot get \"column names\" or other metadata.\n",
    "\n",
    "# Assuming your index was built using `index.add(vectors)`\n",
    "# and you maintained a list where list_item[i] corresponds to vector i.\n",
    "# Replace this with your actual loaded data!\n",
    "num_vectors_in_index = index.ntotal\n",
    "original_person_names = [f\"Person_{i:04d}\" for i in range(num_vectors_in_index)]\n",
    "original_file_paths = [f\"/data/DeepGaitV2/person_image_{i:04d}.jpg\" for i in range(num_vectors_in_index)]\n",
    "\n",
    "# In a real application, you would load these from a file (e.g., CSV, JSON, Pickle, database)\n",
    "# Example:\n",
    "# import pickle\n",
    "# with open('data_DeepGaitV2/person_names_mapping.pkl', 'rb') as f:\n",
    "#     original_person_names = pickle.load(f)\n",
    "# with open('data_DeepGaitV2/file_paths_mapping.pkl', 'rb') as f:\n",
    "#     original_file_paths = pickle.load(f)\n",
    "\n",
    "if not original_person_names or len(original_person_names) != num_vectors_in_index:\n",
    "    print(\"\\nWARNING: The 'original_person_names' list does not match the index size or is empty.\")\n",
    "    print(\"This means the mapping is incorrect or missing. You will not get meaningful results.\")\n",
    "    print(\"Please replace the dummy 'original_person_names' with your actual data mapping.\")\n",
    "\n",
    "\n",
    "# --- 4. Simulate a search query and retrieve results ---\n",
    "print(\"\\n--- Performing a sample search ---\")\n",
    "\n",
    "# Create a dummy query vector (must match the index's dimension)\n",
    "# In a real scenario, this would be an embedding from a new person's gait data\n",
    "query_vector = np.random.rand(1, index.d).astype('float32')\n",
    "\n",
    "k = 5  # Number of nearest neighbors to retrieve\n",
    "distances, faiss_internal_ids = index.search(query_vector, k)\n",
    "\n",
    "print(f\"Query vector shape: {query_vector.shape}\")\n",
    "print(f\"Found {k} nearest neighbors:\")\n",
    "print(f\"Distances (L2/Euclidean if IndexFlatL2): {distances}\")\n",
    "print(f\"FAISS Internal IDs (these are indices within the FAISS structure): {faiss_internal_ids}\")\n",
    "\n",
    "# --- 5. Use the FAISS IDs to retrieve your associated data ---\n",
    "print(\"\\n--- Retrieved Associated Data for Nearest Neighbors ---\")\n",
    "\n",
    "# faiss_internal_ids is typically a 2D array (num_queries, k)\n",
    "# We take the first query's results: faiss_internal_ids[0]\n",
    "for i, internal_id in enumerate(faiss_internal_ids[0]):\n",
    "    if 0 <= internal_id < len(original_person_names):\n",
    "        person_name = original_person_names[internal_id]\n",
    "        file_path = original_file_paths[internal_id]\n",
    "        distance = distances[0][i] # distances is also 2D\n",
    "        print(f\"Rank {i+1}: FAISS ID: {internal_id}, Name: '{person_name}', File Path: '{file_path}', Distance: {distance:.4f}\")\n",
    "    else:\n",
    "        print(f\"Rank {i+1}: FAISS ID: {internal_id} - WARNING: ID out of bounds for your external mapping. Data missing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1bc37ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed data/person_database.index\n",
      "Database reset complete\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define database paths\n",
    "db_path = \"data/person_database\"\n",
    "\n",
    "# Remove database files if they exist\n",
    "for ext in [\".index\", \".pkl\"]:\n",
    "    if os.path.exists(db_path + ext):\n",
    "        os.remove(db_path + ext)\n",
    "        print(f\"Removed {db_path}{ext}\")\n",
    "\n",
    "print(\"Database reset complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59a7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Check saved database for face embeddings\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "from utils.database import PersonEmbeddingDatabase\n",
    "\n",
    "def check_saved_database():\n",
    "    \"\"\"Check if face embeddings are saved in the database\"\"\"\n",
    "    print(\"=== Checking Saved Database for Face Embeddings ===\")\n",
    "    \n",
    "    # Try to load existing database\n",
    "    db_paths = [\n",
    "        \"data_DeepGaitV2/person_database\",\n",
    "        \"person_database\",\n",
    "        \"data/person_database\"\n",
    "    ]\n",
    "    \n",
    "    loaded = False\n",
    "    db = PersonEmbeddingDatabase()\n",
    "    \n",
    "    for db_path in db_paths:\n",
    "        if os.path.exists(f\"{db_path}.meta\") and os.path.exists(f\"{db_path}.index\"):\n",
    "            print(f\"Found database at: {db_path}\")\n",
    "            try:\n",
    "                db.load_from_disk(db_path)\n",
    "                loaded = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load database from {db_path}: {e}\")\n",
    "    \n",
    "    if not loaded:\n",
    "        print(\"No database found or failed to load.\")\n",
    "        print(\"Available files in current directory:\")\n",
    "        for file in os.listdir('.'):\n",
    "            if file.endswith('.meta') or file.endswith('.index'):\n",
    "                print(f\"  {file}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nDatabase loaded successfully!\")\n",
    "    print(f\"Total people in database: {len(db.people)}\")\n",
    "    \n",
    "    # Check face embedding statistics\n",
    "    people_with_faces = 0\n",
    "    people_with_gait = 0\n",
    "    total_face_embeddings = 0\n",
    "    total_gait_embeddings = 0\n",
    "    \n",
    "    print(\"\\nPerson details:\")\n",
    "    for person_id, data in db.people.items():\n",
    "        has_face = 'face_embeddings' in data and len(data['face_embeddings']) > 0\n",
    "        has_gait = 'gait_embeddings' in data and len(data['gait_embeddings']) > 0\n",
    "        \n",
    "        face_count = len(data.get('face_embeddings', []))\n",
    "        gait_count = len(data.get('gait_embeddings', []))\n",
    "        \n",
    "        print(f\"  {data['name']} ({person_id}):\")\n",
    "        print(f\"    Gait embeddings: {gait_count}\")\n",
    "        print(f\"    Face embeddings: {face_count}\")\n",
    "        print(f\"    Quality: {data.get('quality', 'N/A')}\")\n",
    "        print(f\"    Data keys: {list(data.keys())}\")\n",
    "        \n",
    "        if has_face:\n",
    "            people_with_faces += 1\n",
    "            total_face_embeddings += face_count\n",
    "        if has_gait:\n",
    "            people_with_gait += 1\n",
    "            total_gait_embeddings += gait_count\n",
    "    \n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"  People with gait embeddings: {people_with_gait}\")\n",
    "    print(f\"  People with face embeddings: {people_with_faces}\")\n",
    "    print(f\"  Total gait embeddings: {total_gait_embeddings}\")\n",
    "    print(f\"  Total face embeddings: {total_face_embeddings}\")\n",
    "    \n",
    "    # Test face identification if we have face embeddings\n",
    "    if total_face_embeddings > 0:\n",
    "        print(f\"\\nTesting face identification...\")\n",
    "        for person_id, data in db.people.items():\n",
    "            if 'face_embeddings' in data and len(data['face_embeddings']) > 0:\n",
    "                test_embedding = data['face_embeddings'][0]\n",
    "                matches = db.identify_person_face(test_embedding, threshold=0.5)\n",
    "                print(f\"  Face ID test for {data['name']}: {len(matches)} matches\")\n",
    "                if matches:\n",
    "                    best_match = matches[0]\n",
    "                    print(f\"    Best match: {best_match[2]} (similarity: {best_match[1]:.3f})\")\n",
    "                break\n",
    "    \n",
    "    print(\"\\n=== Check Complete ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_saved_database()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
